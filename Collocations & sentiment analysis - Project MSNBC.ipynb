{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocations & sentiment analysis - MSNBC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusfolder ='./corpora/MSNBC transcripts/'       \n",
    "corpusfile = corpusfolder + 'MSNBC_withmetadata.csv'         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate corpusfile into months - months in column 3 or MonthNr\n",
    "import pandas as pd \n",
    "\n",
    "file = pd.read_csv(corpusfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "march = 114\n",
    "april = 249\n",
    "may = 368\n",
    "june = 479\n",
    "july = 593\n",
    "august = 664\n",
    "september = 735"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define categories of interest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1_words = set(['social distancing', 'social distance', 'six feet', 'face masks', 'mask', 'masks', 'quarantine', 'lockdown'])\n",
    "cat2_words = set()\n",
    "# # Specify the word list for each category in term_list\n",
    "nrcategories = 1\n",
    "term_list = [cat1_words, cat2_words]\n",
    "cat_names = ['Social Distancing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsmatter = False\n",
    "\n",
    "countstems = False\n",
    "\n",
    "catsexclusive = True\n",
    "\n",
    "sentencefilter = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore anything specified for the second category list if we have just 1 category\n",
    "if nrcategories == 1:\n",
    "    term_list[1] = set()\n",
    "\n",
    "# Lower-case search terms if caps don't matter.\n",
    "if not capsmatter:\n",
    "    term_list = [set(x.lower() for x in terms) for terms in term_list]\n",
    "\n",
    "# Get a list of all terms from either category\n",
    "allterms = {x for terms in term_list for x in list(terms)}\n",
    "\n",
    "# wordsonly marks whether all the terms in term_list are single words/stems\n",
    "# as opposed to multi-word phrases\n",
    "wordsonly = not any([' ' in x for x in allterms])\n",
    "if wordsonly:\n",
    "    cat_words = allterms\n",
    "else:\n",
    "    cat_words = set([x for term in allterms for x in term.split()])\n",
    "    # add word boundary markers at start (and optionally end)\n",
    "    term_list = [set(['\\\\b' + searchterm + ('' if countstems else '\\\\b') \\\n",
    "                      for searchterm in terms]) \\\n",
    "                 for terms in term_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_match(text, cat_terms, countstems=False, wordsonly=True):\n",
    "    \"\"\"See if the text contains any terms in cat_terms.\"\"\"\n",
    "    import re\n",
    "    if len(cat_terms) == 0:\n",
    "        return False\n",
    "    if wordsonly:  # single-word search terms\n",
    "        wordlist = text.split()\n",
    "        words = set(wordlist)\n",
    "        if countstems:\n",
    "            match = any([word[:len(term)] == term \\\n",
    "                         for word in words for term in cat_terms])\n",
    "        else:\n",
    "            match = len(cat_terms.intersection(words)) > 0\n",
    "    else:  # multi-word search terms; use re module to match\n",
    "        match = any([re.search(term, text) is not None for term in cat_terms])\n",
    "    return match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text, cat1_terms, cat2_terms, countstems=False, wordsonly=True):\n",
    "    \"\"\"Check for presence of terms from each list in the text.\"\"\"\n",
    "    if not capsmatter:\n",
    "        text = text.lower()\n",
    "        # Assume terms are already lower-case\n",
    "    if cat_match(text, cat1_terms, countstems, wordsonly):\n",
    "        if cat_match(text, cat2_terms, countstems, wordsonly):\n",
    "            return 3  # match both\n",
    "        else:\n",
    "            return 1\n",
    "    elif cat_match(text, cat2_terms, countstems, wordsonly):\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_counts(words, cat, word_counter, word_freq):\n",
    "    \"\"\"Increment global word counters based on category\"\"\"\n",
    "    word_counter[cat] += len(words)\n",
    "    for word in words:\n",
    "        if word not in word_freq[0]:\n",
    "            for x in range(4):\n",
    "                word_freq[x][word] = 0\n",
    "        word_freq[cat][word] += 1\n",
    "    return word_counter, word_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_caps(word, capitalization):\n",
    "    \"\"\"Check if word is capitalized.\"\"\"\n",
    "    word_nocap = word.lower()\n",
    "    if word_nocap not in capitalization[0]:\n",
    "        capitalization[0][word_nocap] = 0\n",
    "        capitalization[1][word_nocap] = 0\n",
    "    capitalization[0][word_nocap] += 1\n",
    "    if word[0] == word[0].upper():  # optional addition for numbers: and word[0] not in '0123456789'\n",
    "        capitalization[1][word_nocap] += 1\n",
    "    return capitalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemofword(word, stems):\n",
    "    return any([stem == word[:len(stem)] for stem in stems])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentencefilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5a. Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_texts(corpusfile, term_list, nrcategories, capsmatter=False,\n",
    "                  sentencefilter=True, countstems=False):\n",
    "    \"\"\"Main text analysis function.\"\"\"\n",
    "    import csv\n",
    "    csv.field_size_limit(10000000)\n",
    "    \n",
    "    # Define main variables to track words, etc.\n",
    "    article_counter, sentence_counter, word_counter = \\\n",
    "        [0,0,0,0], [0,0,0,0], [0,0,0,0]\n",
    "    cat_texts  = [[], [], [], []]     # containers for selected text\n",
    "    word_freq = [{}, {}, {}, {}]      # dictionary for words encountered\n",
    "    capitalization_record = [{}, {}]  # record of words capitalized\n",
    "    \n",
    "    cat1_terms = term_list[0]\n",
    "    cat2_terms = term_list[1]\n",
    "\n",
    "    sent_counter = 0\n",
    "    articles = 0\n",
    "    \n",
    "    with open(corpusfile, 'r') as texts:\n",
    "\n",
    "        for text_counter, row in enumerate(csv.reader(texts)):\n",
    "            \n",
    "            if text_counter <= march: #change month parameters \n",
    "                text = row[7]\n",
    "                textcat = classify_text(text, cat1_terms, cat2_terms, countstems)\n",
    "                article_counter[textcat] += 1\n",
    "                articles +=1\n",
    "\n",
    "                for sentence in text.split('.'):\n",
    "                    sent_counter += 1\n",
    "                    sent_words = sentence.split()\n",
    "                    # figure out how often each word is capitalized (except 1st word in sentence)\n",
    "                    for word in sent_words[1:]:\n",
    "                        capitalization_record = check_caps(word, capitalization_record) \n",
    "\n",
    "                    if sentencefilter:\n",
    "                        # make words lower-case as appropriate \n",
    "                        if not capsmatter:\n",
    "                            sent_words = [w.lower() for w in sent_words]\n",
    "                        sentcat = classify_text(sentence, cat1_terms, cat2_terms, countstems, capsmatter)\n",
    "                        sentence_counter[sentcat] += 1\n",
    "                        word_counter, word_freq = \\\n",
    "                            increment_counts(sent_words, sentcat, word_counter, word_freq)\n",
    "                        cat_texts[sentcat].append(sentence)\n",
    "\n",
    "                if not sentencefilter:\n",
    "                    word_counter, word_freq = \\\n",
    "                        increment_counts([w if capsmatter else w.lower() for w in text.split()], textcat, \n",
    "                                         word_counter, word_freq)\n",
    "                    cat_texts[textcat].append(text)\n",
    "\n",
    "                # Progress update for user\n",
    "                if text_counter % 5000 == 0:\n",
    "                    print(\"Processing article %d\" % (text_counter,))\n",
    "                    \n",
    "        \n",
    "\n",
    "    print(\"Processed %d sentences in %d articles\" % (sent_counter, articles))\n",
    "    #print(\"word:\", cat_texts[0][:100])\n",
    "    \n",
    "    return article_counter, sentence_counter, word_counter, \\\n",
    "           word_freq, capitalization_record, cat_texts, sent_counter\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at 2020-11-10 17:36:06.567361\n",
      "Processing article 0\n",
      "Processed 55895 sentences in 115 articles\n",
      "Done at 2020-11-10 17:36:10.741039\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting at\", datetime.now())\n",
    "\n",
    "article_counter, sentence_counter, word_counter, word_freq, \\\n",
    "    word_caps, cat_texts, nrsentences = \\\n",
    "        analyze_texts(corpusfile, term_list, nrcategories, capsmatter,\n",
    "                      sentencefilter, countstems)\n",
    "\n",
    "print(\"Done at\", datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Vader sentiment dictionary contains 7534 entries.\n",
      "The average valence is -0.18.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Specify sentiment lexicon location\n",
    "sentdictfile = './corpora/more_vader.csv' \n",
    "\n",
    "sentiment_dict = {}\n",
    "\n",
    "# Read data into dictionary\n",
    "with open(sentdictfile, 'r') as dictfile:\n",
    "    for row in csv.reader(dictfile):\n",
    "        if len(row) >= 2:\n",
    "            sentiment_dict[row[0]] = float(row[1])\n",
    "\n",
    "nr_entries = len(sentiment_dict)\n",
    "print('The Vader sentiment dictionary contains {} entries.'.format(nr_entries))\n",
    "\n",
    "avg_valence = sum([x[1] for x in sentiment_dict.items()]) / nr_entries\n",
    "print('The average valence is {:4.2f}.'.format(avg_valence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(texts, sentiment_dict, aggregation='simple'):\n",
    "    \"\"\"Return a sentiment value for each text in texts.\n",
    "    \n",
    "    Aggregation options: 'simple' sum (positive words - negative words),\n",
    "    or 'scaled' sum (simple sum / length of text).\n",
    "    \"\"\"\n",
    "    list_total_sentiment = []\n",
    "    for text in texts:\n",
    "        text_sentiment_values = []\n",
    "        words = text.split(\" \")\n",
    "        for word in words:\n",
    "            if word in sentiment_dict.keys():\n",
    "                text_sentiment_values.append(sentiment_dict.get(word))\n",
    "        Sum = sum(text_sentiment_values)\n",
    "        list_total_sentiment.append(Sum)\n",
    "            \n",
    "    if aggregation == 'simple':\n",
    "        return list_total_sentiment\n",
    "    \n",
    "    if aggregation == 'scaled':\n",
    "        scaled_list = []\n",
    "        for i in range(0, len(texts)): #i is index of sentence and its sentiment value in their corresponding lists\n",
    "            words = texts[i].split(\" \")\n",
    "            len_sentence = len(words)\n",
    "            text_sentiment = list_total_sentiment[i]\n",
    "            scaled = text_sentiment/len_sentence\n",
    "            scaled_list.append(scaled)\n",
    "        return scaled_list  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_data = [get_sentiment(one_category, sentiment_dict, aggregation='simple') \\\n",
    "                  for one_category in cat_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54756.0\n",
      "1139.0\n"
     ]
    }
   ],
   "source": [
    "for cat_sent in sentiment_data[:2]:\n",
    "    print(float(len(cat_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentiment for non-matching sentences:  0.08\n",
      "Average sentiment for Social Distancing sentences: 0.037\n"
     ]
    }
   ],
   "source": [
    "avg_sentiment = [sum(cat_sentiment)/float(len(cat_sentiment)) \\\n",
    "                 for cat_sentiment in sentiment_data[:2]]\n",
    "\n",
    "print(\"Average sentiment for non-matching sentences: %5.2f\" % avg_sentiment[0])\n",
    "print(\"Average sentiment for %s sentences: %5.3f\" % (cat_names[0], avg_sentiment[1]))\n",
    "#print(\"Average sentiment for %s sentences: %5.3f\" % (cat_names[1], avg_sentiment[2]))\n",
    "#print(\"Average sentiment for sentences containing both: %5.3f\" % avg_sentiment[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for the various counts, so we don't have to keep accessing a list\n",
    "cat0_nrwords = float(word_counter[0])\n",
    "cat1_nrwords = float(word_counter[1])\n",
    "cat2_nrwords = float(word_counter[2])\n",
    "cat3_nrwords = float(word_counter[3])\n",
    "\n",
    "# Analogous values for sentences/articles.\n",
    "cat0_texts = float(sentence_counter[0]) if sentencefilter else float(article_counter[0])\n",
    "cat1_texts = float(sentence_counter[1]) if sentencefilter else float(article_counter[1])\n",
    "cat2_texts = float(sentence_counter[2]) if sentencefilter else float(article_counter[2])\n",
    "cat3_texts = float(sentence_counter[3]) if sentencefilter else float(article_counter[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 1038064. Total number of distinct words: 18438.\n"
     ]
    }
   ],
   "source": [
    "# Get total word count, and total count for each individual word\n",
    "corpuslen = cat0_nrwords + cat1_nrwords + cat2_nrwords + cat3_nrwords\n",
    "\n",
    "print(\"Total number of words: %d. Total number of distinct words: %d.\" % \\\n",
    "      (corpuslen, len(word_freq[0].items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_common = True\n",
    "filter_catwords = True\n",
    "filter_stems = False  \n",
    "filter_bylist = True\n",
    "filter_frequency = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different words: 18438\n"
     ]
    }
   ],
   "source": [
    "# Filter 1: most common words in either category\n",
    "if filter_common:\n",
    "    topN = 25000  # the number of top words, per category, to include\n",
    "                   # note: the top will likely overlap, so this will not produce 2*topN words\n",
    "    allcatwords = set([w[0] for w in sorted(word_freq[1].items(), \n",
    "                                            key=lambda x: x[1],\n",
    "                                            reverse=True)[:topN]])\n",
    "    if nrcategories == 2:\n",
    "        allcatwords |= set([w[0] for w in sorted(word_freq[2].items(),\n",
    "                                                 key=lambda x: x[1],\n",
    "                                                 reverse=True)[:topN]])  \n",
    "else:\n",
    "    allcatwords = set(word_freq[0].keys())\n",
    "    \n",
    "print(\"Number of different words: %d\" % len(allcatwords))\n",
    "allcatwordsfull = allcatwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter 2: Remove any words in our categories\n",
    "if filter_catwords:\n",
    "    allcatwords -= allterms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter 3: Remove words beginning with one of our search terms\n",
    "if filter_stems:\n",
    "    allcatwords = {w for w in allcatwords if not stemofword(w, allterms)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_bylist:\n",
    "    allcatwords &= set(sentiment_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different words: 2104\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of different words: %d\" % len(allcatwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "if corpuslen == 0:\n",
    "    print(\"No words found: error in processing\")\n",
    "else:\n",
    "    word_ratios = {w: (word_freq[0][w] + word_freq[1][w] + \\\n",
    "                       word_freq[2][w] + word_freq[3][w]) / corpuslen\n",
    "                   for w in allcatwords}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate frequency ratios for remaining words; go with per-word ratio for now\n",
    "# To go with sentences/articles instead, replace cat0_nrwords by cat0_texts, etc.\n",
    "\n",
    "if cat0_nrwords == 0:   \n",
    "    cat0_ratios = {w: 0 for w in allcatwords}\n",
    "else:\n",
    "    cat0_ratios = {w: word_freq[0][w] / cat0_nrwords for w in allcatwords}\n",
    "\n",
    "if catsexclusive:  # exclude category 3 results (makes difference only for nrcats == 2)\n",
    "    if cat1_nrwords == 0:\n",
    "        cat1_ratios = {w: 0 for w in allcatwords}\n",
    "    else:\n",
    "        cat1_ratios = {w: word_freq[1][w] / cat1_nrwords\n",
    "                       for w in allcatwords}\n",
    "    if cat2_nrwords == 0:\n",
    "        cat2_ratios = {w: 0 for w in allcatwords}\n",
    "    else:\n",
    "        cat2_ratios = {w: word_freq[2][w] / cat2_nrwords\n",
    "                       for w in allcatwords}\n",
    "    \n",
    "else:  # add in category 3 results\n",
    "    cat1_nrwordsX = cat1_nrwords + cat3_nrwords\n",
    "    cat2_nrwordsX = cat2_nrwords + cat3_nrwords\n",
    "    if cat1_nrwordsX == 0:\n",
    "        cat1_ratios = {w: 0 for w in allcatwords}\n",
    "    else:\n",
    "        cat1_ratios = {w: (word_freq[1][w] + word_freq[3][w]) / cat1_nrwordsX\n",
    "                       for w in allcatwords}\n",
    "    if cat2_nrwordsX == 0:\n",
    "        cat2_ratios = {w: 0 for w in allcatwords}\n",
    "    else:\n",
    "        cat2_ratios = {w: (word_freq[2][w] + word_freq[3][w]) / cat2_nrwordsX\n",
    "                       for w in allcatwords}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter 5: Frequency of occurrence:\n",
    "# - compare frequency in target category against baseline frequency\n",
    "# - compare frequency in target category against threshold\n",
    "\n",
    "if filter_frequency:\n",
    "    baseline_threshold = 1.5  # Frequency should be x * greater than baseline frequency\n",
    "    min_threshold = 0.00001   # Frequency in a category of interest (either one, if we have\n",
    "                              # two categories) should exceed this threshold\n",
    "    allcatwords = {w for w in allcatwords \\\n",
    "                   if max(cat0_ratios[w] * baseline_threshold, min_threshold) < \\\n",
    "                      max(cat1_ratios[w], cat2_ratios[w])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_threshold = 0.667  \n",
    "proper_nouns = \\\n",
    "    set([word for word in allcatwords if  \n",
    "             word.lower() in word_caps[0] and \\\n",
    "                 (cap_threshold < word_caps[1][word.lower()] / float(word_caps[0][word.lower()]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All words left: 2104. Non-proper noun words left: 2056\n"
     ]
    }
   ],
   "source": [
    "# Filter 5: Remove proper nouns; store as separate list\n",
    "allcatwords_noproper = allcatwords - proper_nouns\n",
    "\n",
    "# Now let's see how many words we're left with\n",
    "print(\"All words left: %d. Non-proper noun words left: %d\" % \\\n",
    "      (len(allcatwords), len(allcatwords_noproper)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "eps = sys.float_info.epsilon\n",
    "\n",
    "# First, category 1 against all text (categories 0 through 3 combined)\n",
    "PMI_baseline1 = {w: -9.99 if cat1_ratios[w] == 0 \\\n",
    "                     else math.log(cat1_ratios[w] / word_ratios[w]) \\\n",
    "                     for w in allcatwords}\n",
    "# Two additional measures if we have 2 categories\n",
    "if nrcategories > 1:\n",
    "    ratio_relative = {w: (cat1_ratios[w] / (cat1_ratios[w] + cat2_ratios[w])) \\\n",
    "                        for w in allcatwords if cat1_ratios[w] > 0}\n",
    "    PMI_baseline2 = {w: -9.99 if cat2_ratios[w] == 0 \\\n",
    "                        else math.log(cat2_ratios[w] / word_ratios[w]) \\\n",
    "                        for w in allcatwords}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Display results\n",
    "\n",
    "### 8a. Overall frequency patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55895 total sentences; 2.04% category-specific\n",
      "\n",
      "1139 sentences contain Social Distancing (2.04%).\n"
     ]
    }
   ],
   "source": [
    "total_texts = cat0_texts + cat1_texts + cat2_texts + cat3_texts \n",
    "\n",
    "descriptor = 'sentence' if sentencefilter else 'article'\n",
    "\n",
    "print('%d total %ss; %.2f%% category-specific' % \\\n",
    "      (total_texts, descriptor, 100 * (cat1_texts + cat2_texts + cat3_texts) / total_texts))                                \n",
    "print('\\n%d %ss contain %s (%.2f%%).' % \\\n",
    "      (int(cat1_texts), descriptor, cat_names[0], 100 * cat1_texts / total_texts))\n",
    "\n",
    "if nrcategories == 2:\n",
    "    print('%d %ss contain %s (%.2f%%).' % \\\n",
    "          (int(cat2_texts), descriptor, cat_names[1], 100 * cat2_texts / total_texts))\n",
    "    print('%d %ss contain both (%.2f%%).' % \\\n",
    "          (int(cat3_texts), descriptor, 100 * cat3_texts / total_texts))\n",
    "    if cat2_texts != 0:\n",
    "        print('\\n%.1f %ss about %s only for each %s about %s only.' % \\\n",
    "              (cat1_texts / cat2_texts, descriptor, cat_names[0], descriptor, cat_names[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8b. Top results by metric (no proper nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getwords(metriclist, properfilter=False, reverse=True):\n",
    "    if properfilter:\n",
    "        metriclist = {w: val for w, val in metriclist.items() if w in allcatwords_noproper}\n",
    "    return sorted(metriclist, key=metriclist.get, reverse=reverse)\n",
    "\n",
    "def getdata(cat, wordlist, ratiovals, metricvals, nrwords, mincount=1):\n",
    "    datalist = [(w, word_freq[cat][w], ratiovals[w], metricvals[w]) for w in wordlist \\\n",
    "                if word_freq[cat][w] >= mincount]\n",
    "    if len(datalist) >= nrwords:\n",
    "        return datalist[:nrwords]\n",
    "    else:\n",
    "        return datalist + [('-', 0, 0, -9.99) for x in range(nrwords - len(datalist))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display1list(catdata):\n",
    "    print(\"\\nCategory 1      (word, count, frequency, PMI)\")\n",
    "    for w, count, freq, PMI in catdata:\n",
    "        print(\"%18s %6d %8.5f %5.2f\" % (w, count, freq, PMI))\n",
    "\n",
    "def display2lists(catdata):\n",
    "    print(\"\\nCategory 1 (word, count, frequency, PMI)  Category 2 (word, count, frequency, PMI)\")\n",
    "    for w1, count1, freq1, PMI1, w2, count2, freq2, PMI2 in catdata:\n",
    "        print(\"%18s %6d %8.5f %5.2f %19s %6d %8.5f %5.2f\" % \\\n",
    "              (w1, count1, freq1, PMI1, w2, count2, freq2, PMI2))\n",
    "\n",
    "def displaycomplists(catdata):\n",
    "    print(\"\\nCateg.1 (word, count, frequency, metric)  Categ.2 (word, count, frequency, metric)\")\n",
    "    for w1, count1, freq1, PMI1, w2, count2, freq2, PMI2 in catdata:\n",
    "        print(\"%18s %6d %8.5f %5.2f %19s %6d %8.5f %5.2f\" % \\\n",
    "              (w1, count1, freq1, PMI1, w2, count2, freq2, PMI2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swapratiorel(ratiorelative):\n",
    "    \"\"\"Convert from ratio1/(ratio1 + ratio2) to ratio2/(ratio1 + ratio2)\"\"\"\n",
    "    return {w: 1 - val for w, val in ratiorelative.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def displayresults(nopropers=True, nrwords=50, mincount=1):\n",
    "    \"\"\"Display result lists, with frequency & PMI information.\"\"\"\n",
    "    \n",
    "    print(\"Selection criteria:\")\n",
    "    print(\"\\nCategory 1: %s\" % (cat_names[0]))\n",
    "    #print(\"\\nCategory 2: %s\" % (cat_names[1]))\n",
    "    \n",
    "    # Calculate top words of category 1 vs. baseline (category 0)\n",
    "    cat1words = getwords(PMI_baseline1, properfilter=nopropers)\n",
    "    cat1data = getdata(1, cat1words, cat1_ratios, PMI_baseline1, \n",
    "                       nrwords, mincount=mincount)\n",
    "\n",
    "    print(\"\\nTop category words, comparing against baseline.\")\n",
    "    print(\"Measure: PMI (value > 0 means more prevalent in category than in baseline)\")\n",
    "\n",
    "    if nrcategories == 1:\n",
    "        display1list(cat1data)\n",
    "\n",
    "    else:  # assume 2 categories\n",
    "\n",
    "        # Calculate top words of category 2 vs. baseline\n",
    "        cat2words = getwords(PMI_baseline2, properfilter=nopropers)\n",
    "        cat2data = getdata(2, cat2words, cat2_ratios, PMI_baseline2, \n",
    "                           nrwords, mincount=mincount)\n",
    "        bothcatsdata = [c1 + c2 for c1, c2 in zip(cat1data, cat2data)]\n",
    "        display2lists(bothcatsdata)\n",
    "\n",
    "        # Now calculate & display salience between categories\n",
    "        cat1words_rel = getwords(ratio_relative, properfilter=nopropers, reverse=True)\n",
    "        cat2words_rel = getwords(ratio_relative, properfilter=nopropers, reverse=False)\n",
    "        cat1data_rel = getdata(1, cat1words_rel, cat1_ratios, ratio_relative,\n",
    "                               nrwords, mincount=mincount)\n",
    "        cat2data_rel = getdata(2, cat2words_rel, cat2_ratios, swapratiorel(ratio_relative),\n",
    "                               nrwords, mincount=mincount)\n",
    "        bothcatsdata = [c1 + c2 for c1, c2 in zip(cat1data_rel, cat2data_rel)]\n",
    "\n",
    "        print(\"\\nTop category words, comparing categories to one another.\")\n",
    "        print(\"Measure: category word ratio / sum of both category ratios\")\n",
    "        print(\"(value > 0.5 means more prevalent in this category)\")\n",
    "\n",
    "        displaycomplists(bothcatsdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection criteria:\n",
      "\n",
      "Category 1: Social Distancing\n",
      "\n",
      "Top category words, comparing against baseline.\n",
      "Measure: PMI (value > 0 means more prevalent in category than in baseline)\n",
      "\n",
      "Category 1      (word, count, frequency, PMI)\n",
      "           wearing     30  0.00087  2.74\n",
      "              wear     19  0.00055  2.54\n",
      "          shortage     15  0.00043  1.79\n",
      "         shortages     11  0.00032  1.62\n",
      "          guidance     11  0.00032  1.33\n",
      "        aggressive     10  0.00029  1.23\n",
      "           protect     23  0.00066  1.03\n",
      "           exposed     11  0.00032  1.03\n",
      "              hand     12  0.00035  0.94\n",
      "          critical     13  0.00038  0.76\n",
      "          infected     13  0.00038  0.47\n",
      "              care     55  0.00159  0.45\n",
      "              best     18  0.00052  0.36\n",
      "              stop     10  0.00029  0.35\n",
      "              need    110  0.00318  0.31\n",
      "              sick     17  0.00049  0.28\n",
      "            pretty     10  0.00029  0.19\n",
      "            deaths     10  0.00029  0.12\n",
      "              kind     28  0.00081  0.12\n",
      "               not    188  0.00543  0.10\n",
      "         important     20  0.00058  0.05\n",
      "                no     47  0.00136  0.03\n",
      "          positive     11  0.00032 -0.02\n",
      "            number     27  0.00078 -0.15\n",
      "              like     76  0.00220 -0.15\n",
      "           problem     12  0.00035 -0.36\n",
      "             cases     28  0.00081 -0.39\n",
      "              help     13  0.00038 -0.54\n",
      "              sure     14  0.00040 -0.59\n",
      "              well     34  0.00098 -0.60\n",
      "           testing     22  0.00064 -0.60\n",
      "              want     19  0.00055 -0.96\n",
      "              good     12  0.00035 -1.00\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n"
     ]
    }
   ],
   "source": [
    "displayresults(nopropers=True, nrwords=50, mincount=10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8c. Results with proper nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection criteria:\n",
      "\n",
      "Category 1: Social Distancing\n",
      "\n",
      "Top category words, comparing against baseline.\n",
      "Measure: PMI (value > 0 means more prevalent in category than in baseline)\n",
      "\n",
      "Category 1      (word, count, frequency, PMI)\n",
      "           wearing     30  0.00087  2.74\n",
      "              wear     19  0.00055  2.54\n",
      "          shortage     15  0.00043  1.79\n",
      "         shortages     11  0.00032  1.62\n",
      "          guidance     11  0.00032  1.33\n",
      "        aggressive     10  0.00029  1.23\n",
      "           defense     16  0.00046  1.10\n",
      "           protect     23  0.00066  1.03\n",
      "           exposed     11  0.00032  1.03\n",
      "              hand     12  0.00035  0.94\n",
      "          critical     13  0.00038  0.76\n",
      "          infected     13  0.00038  0.47\n",
      "              care     55  0.00159  0.45\n",
      "              best     18  0.00052  0.36\n",
      "              stop     10  0.00029  0.35\n",
      "              need    110  0.00318  0.31\n",
      "              sick     17  0.00049  0.28\n",
      "            pretty     10  0.00029  0.19\n",
      "            deaths     10  0.00029  0.12\n",
      "              kind     28  0.00081  0.12\n",
      "               not    188  0.00543  0.10\n",
      "         important     20  0.00058  0.05\n",
      "                no     47  0.00136  0.03\n",
      "          positive     11  0.00032 -0.02\n",
      "            number     27  0.00078 -0.15\n",
      "              like     76  0.00220 -0.15\n",
      "           problem     12  0.00035 -0.36\n",
      "             cases     28  0.00081 -0.39\n",
      "              help     13  0.00038 -0.54\n",
      "              sure     14  0.00040 -0.59\n",
      "              well     34  0.00098 -0.60\n",
      "           testing     22  0.00064 -0.60\n",
      "              want     19  0.00055 -0.96\n",
      "              good     12  0.00035 -1.00\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n",
      "                 -      0  0.00000 -9.99\n"
     ]
    }
   ],
   "source": [
    "displayresults(nopropers=False, nrwords=50, mincount=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
